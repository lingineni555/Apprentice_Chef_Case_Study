{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br><h2>Analyzing the Apprentice Chef's First Year Customer </h2>\n",
    "<h4>DAT-5303 | Analysis Report to Management | Individual Assignment</h4>\n",
    "Models used OLS Regression and Tuned Random Forest<br>\n",
    "Created by <a href=\"https://www.linkedin.com/in/linginenivishal/\"> Vishal Lingineni </a> <br>\n",
    "Hult International Business School\n",
    "\n",
    "<h2>Purpose of this Script</h2><br>\n",
    "Developing a consolidated report containing my top actionable insights from the case as well as my final revenue and cross-sell promotion models.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Managment Report</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Brief Introduction </strong><br>\n",
    "Apprentice Chef has been serving customers across the San Francisco’s Bay Area from the past three years. They want to understand how much revenue they can expect from each customer and promote their Halfway-There promotion to a broader audience. To better understand these two tasks, they hired us to analyze their first years’ service data and generate some actionable insights.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Methodology</strong> <br>\n",
    "The Data that we got from the Data Science team contains information about 2000 customers who had at least purchased once per month with a total of 11 purchases or one purchase per quarter with at least 15 purchases throughout their first year.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Actionable Insights </strong>\n",
    "<li>A Customer who has a lengthy name and subscribed using a personal or professional email is more likely to opt for our promotion than a customer who subscribes using junk email.</li>\n",
    "<li>Junk email group has the second most potent influence on our promotion. Only 41% of customers from that group subscribed to our promotion, leaving us potential untapped customers left unexplored. </li>\n",
    "<li>One unit increase in video preparations is expected to improve the revenue from each customer by 0.04%, So having more detailed videos will motivate customers to buy more. </li> \n",
    "<li>Customers registered using any of the three classified email domains given by marketing team will have the same effect on revenue even though their response rates are different.  </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Performance Metrics for the models </strong><br>\n",
    "<li>The Accuracy of the Model predicting expected revenue from each customer is 78.197.</li>\n",
    "<li>The AUC of the Model classifying a potential Halfway-There promotion customer is 76.278.</li> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Conclusion</strong> <br>\n",
    "In conclusion, <i>increasing the duration of preparation instructions </i>will help grow the revenue. Customers from the junk emails category are the least subscriber group to our promotion, so <i>focusing more on them </i>will help us reach more customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>KPI </strong><br>\n",
    "<i>Conversion rate </i>acts as a good way to measure whether we are able to get more customers from junk email section. <br>\n",
    "<i>View-Trough Rate </i>can be used to see how targeted our videos are, along with this we can use <i>conversion rate</i> to check the increase in revenue after the new video is added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Coding Details </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Importing the Dataset </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas            as pd                       # data science essentials\n",
    "import matplotlib.pyplot as plt                      # data visualization\n",
    "import seaborn           as sns                      # enhanced data viz\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "import random as rand                     # random number gen\n",
    "import numpy as np # numpy package\n",
    "from sklearn.linear_model import LinearRegression # linear regression (scikit-learn)\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# specifying file name\n",
    "file = 'Apprentice_Chef_Dataset_Rich.xlsx'\n",
    "\n",
    "# reading the file into Python\n",
    "restarunt = pd.read_excel(io=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1946, 56)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restarunt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Revenue Prediction Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data\n",
      "-------------\n",
      "X-side: (1459, 49)\n",
      "y-side: (1459,)\n",
      "\n",
      "\n",
      "Testing Data\n",
      "------------\n",
      "X-side: (487, 49)\n",
      "y-side: (487,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "restarunt_data   = restarunt.drop(['revenue','revenue_per_order',\n",
    "                                 'log_revenue',\n",
    "                                 'email','first_name','name','family_name'],\n",
    "                               axis = 1)\n",
    "\n",
    "\n",
    "# preparing response variables\n",
    "restarunt_target = restarunt.loc[ : , 'revenue']\n",
    "log_restarunt_target = restarunt.loc[ : , 'log_revenue']\n",
    "\n",
    "\n",
    "\n",
    "# preparing training and testing sets (all letters are lowercase)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            restarunt_data,\n",
    "            log_restarunt_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# checking the shapes of the datasets\n",
    "print(f\"\"\"\n",
    "Training Data\n",
    "-------------\n",
    "X-side: {x_train.shape}\n",
    "y-side: {y_train.shape}\n",
    "\n",
    "\n",
    "Testing Data\n",
    "------------\n",
    "X-side: {x_test.shape}\n",
    "y-side: {y_test.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>log_revenue</td>   <th>  R-squared:         </th> <td>   0.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   259.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>04:04:50</td>     <th>  Log-Likelihood:    </th> <td>  1295.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1459</td>      <th>  AIC:               </th> <td>  -2551.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1439</td>      <th>  BIC:               </th> <td>  -2446.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>    1.8516</td> <td>    0.016</td> <td>  117.978</td> <td> 0.000</td> <td>    1.821</td> <td>    1.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cross_sell_success</th>              <td>   -0.0160</td> <td>    0.006</td> <td>   -2.681</td> <td> 0.007</td> <td>   -0.028</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_meals_ordered</th>             <td>    0.0007</td> <td> 6.27e-05</td> <td>   10.916</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unique_meals_purch</th>              <td>    0.0439</td> <td>    0.003</td> <td>   13.789</td> <td> 0.000</td> <td>    0.038</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_prep_vid_time</th>               <td>    0.0012</td> <td> 9.39e-05</td> <td>   13.305</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>median_meal_rating</th>              <td>    0.1250</td> <td>    0.016</td> <td>    7.633</td> <td> 0.000</td> <td>    0.093</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_master_classes_attended</th>     <td>    0.0421</td> <td>    0.006</td> <td>    6.829</td> <td> 0.000</td> <td>    0.030</td> <td>    0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>has_total_photos_viewed</th>         <td>    0.0289</td> <td>    0.006</td> <td>    4.886</td> <td> 0.000</td> <td>    0.017</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recurring_complaints</th>            <td>   -0.2547</td> <td>    0.013</td> <td>  -19.222</td> <td> 0.000</td> <td>   -0.281</td> <td>   -0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_contacts_w_customer_service</th> <td>    0.2763</td> <td>    0.025</td> <td>   10.961</td> <td> 0.000</td> <td>    0.227</td> <td>    0.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_median_meal_rating</th>          <td>   -0.3571</td> <td>    0.088</td> <td>   -4.073</td> <td> 0.000</td> <td>   -0.529</td> <td>   -0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_largest_order_size</th>          <td>   -0.0572</td> <td>    0.026</td> <td>   -2.221</td> <td> 0.027</td> <td>   -0.108</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_unique_meals_purch</th>          <td>   -0.5555</td> <td>    0.029</td> <td>  -18.925</td> <td> 0.000</td> <td>   -0.613</td> <td>   -0.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk</th>                            <td>    0.6150</td> <td>    0.007</td> <td>   90.243</td> <td> 0.000</td> <td>    0.602</td> <td>    0.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal</th>                        <td>    0.6178</td> <td>    0.006</td> <td>   97.136</td> <td> 0.000</td> <td>    0.605</td> <td>    0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>professional</th>                    <td>    0.6188</td> <td>    0.007</td> <td>   93.322</td> <td> 0.000</td> <td>    0.606</td> <td>    0.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>andy</th>                            <td>    0.3003</td> <td>    0.029</td> <td>   10.283</td> <td> 0.000</td> <td>    0.243</td> <td>    0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>                          <td>    0.2954</td> <td>    0.011</td> <td>   25.888</td> <td> 0.000</td> <td>    0.273</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>                            <td>    0.3170</td> <td>    0.009</td> <td>   34.186</td> <td> 0.000</td> <td>    0.299</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mostly_female</th>                   <td>    0.3211</td> <td>    0.022</td> <td>   14.313</td> <td> 0.000</td> <td>    0.277</td> <td>    0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mostly_male</th>                     <td>    0.3143</td> <td>    0.021</td> <td>   14.739</td> <td> 0.000</td> <td>    0.272</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unknown</th>                         <td>    0.3034</td> <td>    0.008</td> <td>   37.234</td> <td> 0.000</td> <td>    0.287</td> <td>    0.319</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>251.133</td> <th>  Durbin-Watson:     </th> <td>   2.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1536.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.649</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.857</td>  <th>  Cond. No.          </th> <td>1.87e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.34e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            log_revenue   R-squared:                       0.774\n",
       "Model:                            OLS   Adj. R-squared:                  0.771\n",
       "Method:                 Least Squares   F-statistic:                     259.0\n",
       "Date:                Fri, 29 Jan 2021   Prob (F-statistic):               0.00\n",
       "Time:                        04:04:50   Log-Likelihood:                 1295.7\n",
       "No. Observations:                1459   AIC:                            -2551.\n",
       "Df Residuals:                    1439   BIC:                            -2446.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                           1.8516      0.016    117.978      0.000       1.821       1.882\n",
       "cross_sell_success                 -0.0160      0.006     -2.681      0.007      -0.028      -0.004\n",
       "total_meals_ordered                 0.0007   6.27e-05     10.916      0.000       0.001       0.001\n",
       "unique_meals_purch                  0.0439      0.003     13.789      0.000       0.038       0.050\n",
       "avg_prep_vid_time                   0.0012   9.39e-05     13.305      0.000       0.001       0.001\n",
       "median_meal_rating                  0.1250      0.016      7.633      0.000       0.093       0.157\n",
       "has_master_classes_attended         0.0421      0.006      6.829      0.000       0.030       0.054\n",
       "has_total_photos_viewed             0.0289      0.006      4.886      0.000       0.017       0.040\n",
       "recurring_complaints               -0.2547      0.013    -19.222      0.000      -0.281      -0.229\n",
       "log_contacts_w_customer_service     0.2763      0.025     10.961      0.000       0.227       0.326\n",
       "log_median_meal_rating             -0.3571      0.088     -4.073      0.000      -0.529      -0.185\n",
       "log_largest_order_size             -0.0572      0.026     -2.221      0.027      -0.108      -0.007\n",
       "log_unique_meals_purch             -0.5555      0.029    -18.925      0.000      -0.613      -0.498\n",
       "junk                                0.6150      0.007     90.243      0.000       0.602       0.628\n",
       "personal                            0.6178      0.006     97.136      0.000       0.605       0.630\n",
       "professional                        0.6188      0.007     93.322      0.000       0.606       0.632\n",
       "andy                                0.3003      0.029     10.283      0.000       0.243       0.358\n",
       "female                              0.2954      0.011     25.888      0.000       0.273       0.318\n",
       "male                                0.3170      0.009     34.186      0.000       0.299       0.335\n",
       "mostly_female                       0.3211      0.022     14.313      0.000       0.277       0.365\n",
       "mostly_male                         0.3143      0.021     14.739      0.000       0.272       0.356\n",
       "unknown                             0.3034      0.008     37.234      0.000       0.287       0.319\n",
       "==============================================================================\n",
       "Omnibus:                      251.133   Durbin-Watson:                   2.047\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1536.514\n",
       "Skew:                          -0.649   Prob(JB):                         0.00\n",
       "Kurtosis:                       7.857   Cond. No.                     1.87e+18\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 1.34e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging X_train and y_train so that they can be used in statsmodels\n",
    "restarunt_train = pd.concat([x_train, y_train], axis = 1)\n",
    "\n",
    "# blueprinting a OLS fit model type\n",
    "lm_full = smf.ols(formula = \"\"\"log_revenue ~\n",
    "cross_sell_success +\n",
    "total_meals_ordered +\n",
    "unique_meals_purch +\n",
    "avg_prep_vid_time +\n",
    "median_meal_rating +\n",
    "has_master_classes_attended +\n",
    "has_total_photos_viewed +\n",
    "recurring_complaints +\n",
    "log_contacts_w_customer_service +\n",
    "log_median_meal_rating +\n",
    "log_largest_order_size +\n",
    "log_unique_meals_purch +\n",
    "junk +\n",
    "personal +\n",
    "professional +\n",
    "andy +\n",
    "female +\n",
    "male +\n",
    "mostly_female +\n",
    "mostly_male +\n",
    "unknown\"\"\",\n",
    "                  data = restarunt_train)\n",
    "                  \n",
    "# telling Python to run the data through the blueprint\n",
    "results_full = lm_full.fit()\n",
    "\n",
    "\n",
    "# printing the results\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this variables are selected from OLS Fit model\n",
    "x_variables = ['cross_sell_success' ,\n",
    "'total_meals_ordered' ,\n",
    "'unique_meals_purch' ,\n",
    "'avg_prep_vid_time' ,\n",
    "'median_meal_rating' ,\n",
    "'has_master_classes_attended' ,\n",
    "'has_total_photos_viewed' ,\n",
    "'recurring_complaints' ,\n",
    "'log_contacts_w_customer_service' ,\n",
    "'log_median_meal_rating' ,\n",
    "'log_largest_order_size' ,\n",
    "'log_unique_meals_purch' ,\n",
    "'junk' ,\n",
    "'personal' ,\n",
    "'professional',\n",
    "'andy',\n",
    "'female', \n",
    "'male',\n",
    "'mostly_female',\n",
    "'mostly_male',\n",
    "'unknown'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying modelin scikit-learn\n",
    "\n",
    "# preparing x-variables from the OLS model\n",
    "ols_data = restarunt[x_variables]\n",
    "\n",
    "\n",
    "# preparing response variable\n",
    "log_restarunt_target = restarunt['log_revenue']\n",
    "\n",
    "###############################################\n",
    "## setting up more than one train-test split ##\n",
    "###############################################\n",
    "# FULL X-dataset and (normal Y)\n",
    "x_train_FULL, x_test_FULL, y_train_FULL, y_test_FULL = train_test_split(\n",
    "            restarunt_data,     # x-variables\n",
    "            log_restarunt_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)\n",
    "\n",
    "\n",
    "# Selected x-dataset and (normal Y)\n",
    "x_train_OLS, x_test_OLS, y_train_OLS, y_test_OLS = train_test_split(\n",
    "            restarunt_data,     # x-variables\n",
    "            log_restarunt_target,   # y-variable\n",
    "            test_size = 0.25,\n",
    "            random_state = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Training Score : 0.7864\n",
      "OLS Testing Score  : 0.78197\n",
      "OLS Train-Test Gap : 0.00443\n"
     ]
    }
   ],
   "source": [
    "# OLS model using scikit-learn\n",
    "\n",
    "# INSTANTIATING a model object\n",
    "lr = LinearRegression()\n",
    "\n",
    "\n",
    "# FITTING to the training data\n",
    "lr_fit = lr.fit(x_train_OLS, y_train_OLS)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "lr_pred = lr_fit.predict(x_test_OLS)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('OLS Training Score :', lr.score(x_train_OLS, y_train_OLS).round(5))  # using R-square\n",
    "print('OLS Testing Score  :',  lr.score(x_test_OLS, y_test_OLS).round(5)) # using R-square\n",
    "\n",
    "# saving scoring results\n",
    "lr_train_score = lr.score(x_train_OLS, y_train_OLS).round(5)\n",
    "lr_test_score  = lr.score(x_test_OLS, y_test_OLS).round(5)\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('OLS Train-Test Gap :', abs(lr_train_score - lr_test_score).round(5))\n",
    "lr_test_gap = abs(lr_train_score - lr_test_score).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', 3.03)\n",
      "('cross_sell_success', 0.0)\n",
      "('total_meals_ordered', -0.01)\n",
      "('unique_meals_purch', 0.0)\n",
      "('avg_prep_vid_time', 0.04)\n",
      "('median_meal_rating', 0.04)\n",
      "('has_master_classes_attended', 0.01)\n",
      "('has_total_photos_viewed', -0.0)\n",
      "('recurring_complaints', 0.0)\n",
      "('log_contacts_w_customer_service', 0.0)\n",
      "('log_median_meal_rating', -0.01)\n",
      "('log_largest_order_size', 0.01)\n",
      "('log_unique_meals_purch', -0.0)\n",
      "('junk', -0.01)\n",
      "('personal', 0.0)\n",
      "('professional', -0.0)\n",
      "('andy', 0.0)\n",
      "('female', -0.01)\n",
      "('male', -0.01)\n",
      "('mostly_female', 0.0)\n",
      "('mostly_male', -0.04)\n",
      "('unknown', 0.01)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "lr_model_values = zip(restarunt_data[x_variables].columns,\n",
    "                      lr_fit.coef_.round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "lr_model_lst = [('intercept', lr_fit.intercept_.round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in lr_model_values:\n",
    "    lr_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in lr_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model      Train Score      Test Score\n",
      "-----      -----------      ----------\n",
      "\u001b[1mOLS**      0.7864            0.78197\u001b[0m (Log_revenue is the Y variable)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Model      Train Score      Test Score\n",
    "-----      -----------      ----------\n",
    "\\033[1mOLS**      {lr_train_score}            {lr_test_score}\\033[0m (Log_revenue is the Y variable)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cross Sell Success Prediction Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "restarunt_data = restarunt.drop(['cross_sell_success','name','email','first_name','family_name'], axis = 1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "restarunt_response = restarunt.loc[ : , 'cross_sell_success']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            restarunt_data,\n",
    "            restarunt_response,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = restarunt_response)\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "restarunt_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the variables that we selected for predicting cross sell sucess \n",
    "logit_sig2 = ['mobile_number','cancellations_before_noon',\n",
    "            'tastes_and_preferences','pc_logins','early_deliveries','avg_prep_vid_time',\n",
    "              'junk','personal','len_of_name','refrigerated_locker','female','male'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532608\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>cross_sell_success</td> <th>  No. Observations:  </th>  <td>  1459</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  1446</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>  <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2021</td>  <th>  Pseudo R-squ.:     </th>  <td>0.1518</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>04:04:51</td>      <th>  Log-Likelihood:    </th> <td> -777.07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th> <td> -916.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>1.718e-52</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                 <td>   -2.8412</td> <td>    0.684</td> <td>   -4.151</td> <td> 0.000</td> <td>   -4.183</td> <td>   -1.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>len_of_name</th>               <td>    0.0804</td> <td>    0.013</td> <td>    6.211</td> <td> 0.000</td> <td>    0.055</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mobile_number</th>             <td>    0.9237</td> <td>    0.178</td> <td>    5.180</td> <td> 0.000</td> <td>    0.574</td> <td>    1.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cancellations_before_noon</th> <td>    0.2813</td> <td>    0.047</td> <td>    5.989</td> <td> 0.000</td> <td>    0.189</td> <td>    0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tastes_and_preferences</th>    <td>    0.3829</td> <td>    0.137</td> <td>    2.797</td> <td> 0.005</td> <td>    0.115</td> <td>    0.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pc_logins</th>                 <td>    0.2508</td> <td>    0.108</td> <td>    2.324</td> <td> 0.020</td> <td>    0.039</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>early_deliveries</th>          <td>    0.0617</td> <td>    0.028</td> <td>    2.213</td> <td> 0.027</td> <td>    0.007</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_prep_vid_time</th>         <td>    0.0026</td> <td>    0.001</td> <td>    2.057</td> <td> 0.040</td> <td>    0.000</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>refrigerated_locker</th>       <td>    0.5323</td> <td>    0.211</td> <td>    2.517</td> <td> 0.012</td> <td>    0.118</td> <td>    0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk</th>                      <td>   -1.9312</td> <td>    0.173</td> <td>  -11.138</td> <td> 0.000</td> <td>   -2.271</td> <td>   -1.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal</th>                  <td>   -0.6027</td> <td>    0.146</td> <td>   -4.140</td> <td> 0.000</td> <td>   -0.888</td> <td>   -0.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>                      <td>    0.4872</td> <td>    0.168</td> <td>    2.907</td> <td> 0.004</td> <td>    0.159</td> <td>    0.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>                    <td>   -0.6332</td> <td>    0.240</td> <td>   -2.639</td> <td> 0.008</td> <td>   -1.104</td> <td>   -0.163</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     cross_sell_success   No. Observations:                 1459\n",
       "Model:                          Logit   Df Residuals:                     1446\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Fri, 29 Jan 2021   Pseudo R-squ.:                  0.1518\n",
       "Time:                        04:04:51   Log-Likelihood:                -777.07\n",
       "converged:                       True   LL-Null:                       -916.19\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.718e-52\n",
       "=============================================================================================\n",
       "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "Intercept                    -2.8412      0.684     -4.151      0.000      -4.183      -1.500\n",
       "len_of_name                   0.0804      0.013      6.211      0.000       0.055       0.106\n",
       "mobile_number                 0.9237      0.178      5.180      0.000       0.574       1.273\n",
       "cancellations_before_noon     0.2813      0.047      5.989      0.000       0.189       0.373\n",
       "tastes_and_preferences        0.3829      0.137      2.797      0.005       0.115       0.651\n",
       "pc_logins                     0.2508      0.108      2.324      0.020       0.039       0.462\n",
       "early_deliveries              0.0617      0.028      2.213      0.027       0.007       0.116\n",
       "avg_prep_vid_time             0.0026      0.001      2.057      0.040       0.000       0.005\n",
       "refrigerated_locker           0.5323      0.211      2.517      0.012       0.118       0.947\n",
       "junk                         -1.9312      0.173    -11.138      0.000      -2.271      -1.591\n",
       "personal                     -0.6027      0.146     -4.140      0.000      -0.888      -0.317\n",
       "male                          0.4872      0.168      2.907      0.004       0.159       0.816\n",
       "female                       -0.6332      0.240     -2.639      0.008      -1.104      -0.163\n",
       "=============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" cross_sell_success ~\n",
    "len_of_name +\n",
    "mobile_number +\n",
    "cancellations_before_noon +\n",
    "tastes_and_preferences +\n",
    "pc_logins +\n",
    "early_deliveries +\n",
    "avg_prep_vid_time+\n",
    "refrigerated_locker+\n",
    "junk +\n",
    "personal +\n",
    "male  +\n",
    "female \n",
    " \"\"\",\n",
    "                                        data    = restarunt_train)\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all the selected features are having significant P-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the full model\n",
    "restarunt_data   =  restarunt.loc[ : , logit_sig2]\n",
    "restarunt_target =  restarunt.loc[ : , 'cross_sell_success']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            restarunt_data,\n",
    "            restarunt_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = restarunt_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.79712\n",
      "Forest Tuned Testing  ACCURACY: 0.82957\n",
      "Forest Tuned AUC Score        : 0.76278\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# copy/pasting in the best_estimator_ results\n",
    "# to avoid running another RandomizedSearch\n",
    "forest_tuned = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "forest_tuned_fit = forest_tuned.fit(restarunt_data, restarunt_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(5))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(5))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                   y_score = forest_tuned_pred).round(5))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(5) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(5)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(5) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting feature importances\n",
    "plot_feature_importances(forest_tuned_fit,\n",
    "                         train = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 90\n",
      "False Positives: 66\n",
      "False Negatives: 17\n",
      "True Positives : 314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.7971</td>\n",
       "      <td>0.8296</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>(90, 66, 17, 314)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  Training Accuracy  Testing Accuracy  AUC Score   Confusion Matrix\n",
       "0  Tuned Random Forest (Full)             0.7971            0.8296     0.7628  (90, 66, 17, 314)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "tuned_rf_train_acc = forest_tuned_fit.score(x_train, y_train).round(4)\n",
    "tuned_rf_test_acc  = forest_tuned_fit.score(x_test, y_test).round(4)\n",
    "tuned_rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                   y_score = forest_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "Classification_model_performance ={\n",
    "                           'Model Name'         : 'Tuned Random Forest (Full)',\n",
    "                           'Training Accuracy'  : tuned_rf_train_acc,\n",
    "                           'Testing Accuracy'   : tuned_rf_test_acc,\n",
    "                           'AUC Score'          : tuned_rf_auc,\n",
    "                           'Confusion Matrix'   : [(tuned_rf_tn,\n",
    "                                                   tuned_rf_fp,\n",
    "                                                   tuned_rf_fn,\n",
    "                                                   tuned_rf_tp)]}\n",
    "\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "Classification_model_performance = pd.DataFrame(Classification_model_performance)\n",
    "\n",
    "# checking the results\n",
    "Classification_model_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
