{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<br><h2>Analyzing the Apprentice Chef's First Year Customer </h2>\n",
    "<h4>DAT-5303 | Classification Model Development | Individual Assignment</h4>\n",
    "Models used Logistic Regression, CART Tree, Random Forest and Gradient Boosted Machines <br>\n",
    "Created by <a href=\"https://www.linkedin.com/in/linginenivishal/\"> Vishal Lingineni </a> <br>\n",
    "Hult International Business School\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "\n",
    "<h2>Purpose of this Script</h2><br>\n",
    "This script is designed to analyze the Apprentice Chef's First Year Customer Data to predict which customer will subscribe to Halfway There cross-selling promotion.\n",
    "<br>\n",
    "<h2>Analytical Objectives</h2><br>\n",
    "a) Make a prediction for which customers will subscribe to this promotion.<br>\n",
    "b) Identify key features that impact subscription.\n",
    "<br>\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" /><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part I: Importing & Exploring the Data  </h2><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd # data science essentials\n",
    "import matplotlib.pyplot as plt # essential graphical output\n",
    "import seaborn as sns # enhanced graphical output\n",
    "import numpy as np # mathematical essentials\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# specifying file name\n",
    "file = 'Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "# reading the file into Python\n",
    "restarunt = pd.read_excel(io=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "restarunt.columns = map(str.lower, restarunt.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part II: Handling Missing Values </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "revenue                         0\n",
       "cross_sell_success              0\n",
       "name                            0\n",
       "email                           0\n",
       "first_name                      0\n",
       "family_name                    47\n",
       "total_meals_ordered             0\n",
       "unique_meals_purch              0\n",
       "contacts_w_customer_service     0\n",
       "product_categories_viewed       0\n",
       "avg_time_per_site_visit         0\n",
       "mobile_number                   0\n",
       "cancellations_before_noon       0\n",
       "cancellations_after_noon        0\n",
       "tastes_and_preferences          0\n",
       "pc_logins                       0\n",
       "mobile_logins                   0\n",
       "weekly_plan                     0\n",
       "early_deliveries                0\n",
       "late_deliveries                 0\n",
       "package_locker                  0\n",
       "refrigerated_locker             0\n",
       "avg_prep_vid_time               0\n",
       "largest_order_size              0\n",
       "master_classes_attended         0\n",
       "median_meal_rating              0\n",
       "avg_clicks_per_visit            0\n",
       "total_photos_viewed             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the missing values in each column\n",
    "restarunt.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputting the missing values of family name with Unknown\n",
    "restarunt.loc[:,'family_name'].fillna('Unknown',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part III: Feature Engineering </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "restarunt['avg_revenue_per_order'] = 0\n",
    "for index, value in restarunt.iterrows():\n",
    "    if restarunt.loc[index,'revenue'] > 0:\n",
    "        restarunt.loc[index,'avg_revenue_per_order'] = (restarunt.loc[index,'revenue'] / restarunt.loc[index,'total_meals_ordered']).round(0)\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "restarunt['total_deliveries'] = 0\n",
    "restarunt['total_cancellations'] = 0\n",
    "for index, value in restarunt.iterrows():\n",
    "    restarunt.loc[index, 'total_deliveries'] = restarunt.loc[index, 'early_deliveries'] + restarunt.loc[index, 'late_deliveries']\n",
    "    restarunt.loc[index, 'total_cancellations'] = restarunt.loc[index, 'cancellations_before_noon'] + restarunt.loc[index, 'cancellations_after_noon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gmail.com           303\n",
       "protonmail.com      284\n",
       "yahoo.com           274\n",
       "msn.com              72\n",
       "aol.com              69\n",
       "passport.com         64\n",
       "hotmail.com          63\n",
       "live.com             62\n",
       "me.com               59\n",
       "amex.com             30\n",
       "merck.com            28\n",
       "cocacola.com         28\n",
       "jnj.com              28\n",
       "mcdonalds.com        28\n",
       "apple.com            27\n",
       "nike.com             27\n",
       "ge.org               26\n",
       "ibm.com              26\n",
       "dupont.com           26\n",
       "microsoft.com        25\n",
       "chevron.com          25\n",
       "exxon.com            24\n",
       "travelers.com        24\n",
       "unitedhealth.com     24\n",
       "boeing.com           23\n",
       "pg.com               22\n",
       "mmm.com              22\n",
       "caterpillar.com      22\n",
       "verizon.com          22\n",
       "walmart.com          21\n",
       "disney.com           21\n",
       "pfizer.com           20\n",
       "visa.com             20\n",
       "jpmorgan.com         19\n",
       "goldmansacs.com      18\n",
       "unitedtech.com       18\n",
       "cisco.com            18\n",
       "intel.com            17\n",
       "homedepot.com        17\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: splitting personal emails\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in restarunt.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = restarunt.loc[index, 'email'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "# displaying the results\n",
    "email_df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "personal        861\n",
       "professional    696\n",
       "junk            389\n",
       "Name: domain_group, dtype: int64"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_df.columns = ['0' , 'email_domain']\n",
    "#restarunt['email_domain'] = pd.Series(email_df['email_domain'])\n",
    "# defining Emails Domain Groups\n",
    "professional_email_domains = ['@mmm.com', '@amex.com', '@apple.com',\n",
    "                              '@boeing.com', '@caterpillar.com', '@chevron.com',\n",
    "                             '@cisco.com', '@cocacola.com', '@disney.com',\n",
    "                             '@dupont.com', '@exxon.com', '@ge.org', \n",
    "                              '@goldmansacs.com', '@homedepot.com', '@ibm.com',\n",
    "                             '@intel.com', '@jnj.com', '@jpmorgan.com', \n",
    "                              '@mcdonalds.com', '@merck.com', '@microsoft.com',\n",
    "                             '@nike.com', '@pfizer.com', '@pg.com', \n",
    "                              '@travelers.com', '@unitedtech.com', \n",
    "                              '@verizon.com','@visa.com', '@walmart.com',\n",
    "                             '@unitedhealth.com']\n",
    "\n",
    "personal_email_domains     = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "\n",
    "junk_email_domains = ['@me.com','@aol.com','@live.com', '@msn.com', \n",
    "                              '@passport.com','@hotmail.com']\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in email_df['email_domain']:\n",
    "        if '@' + domain in personal_email_domains:\n",
    "            placeholder_lst.append('personal')\n",
    "            \n",
    "        elif '@' + domain in professional_email_domains:\n",
    "            placeholder_lst.append('professional')\n",
    "            \n",
    "        else:\n",
    "            placeholder_lst.append('junk')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "restarunt['domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# checking results\n",
    "restarunt['domain_group'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding categorical variables\n",
    "one_hot_email_domain      = pd.get_dummies(restarunt['domain_group'])\n",
    "\n",
    "# dropping categorical variables after they've been encoded\n",
    "restarunt = restarunt.drop('domain_group', axis = 1)\n",
    "\n",
    "# joining codings together\n",
    "restarunt = restarunt.join([one_hot_email_domain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1946, 34)"
      ]
     },
     "execution_count": 718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restarunt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dummy variable to check whether uses mobile app\n",
    "#restarunt['uses_mobile_app'] = 0\n",
    "#restarunt.loc[restarunt.mobile_logins > 0, 'uses_mobile_app'] = 1\n",
    "# as p-value is to high didnt use in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dummy variable to flag active users basing on their actions\n",
    "#restarunt['high_new_customer_engagement'] = 0\n",
    "\n",
    "#restarunt.loc[(restarunt.mobile_number == 1) & (restarunt.tastes_and_preferences == 1) & (restarunt.weekly_plan == 0),'high_new_customer_engagement' ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restarunt['log_revenue'] = np.log10(restarunt['revenue'])\n",
    "#restarunt['log_avg_time_per_site_visit'] = np.log10(restarunt['avg_time_per_site_visit'])\n",
    "#restarunt['log_avg_prep_vid_time'] = np.log10(restarunt['avg_prep_vid_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "restarunt['len_of_name'] = restarunt[\"name\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        7\n",
       "1       15\n",
       "2       14\n",
       "3       17\n",
       "4       13\n",
       "        ..\n",
       "1941    10\n",
       "1942    17\n",
       "1943    12\n",
       "1944     6\n",
       "1945    14\n",
       "Name: len_of_name, Length: 1946, dtype: int64"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restarunt['len_of_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy variable for doing cooking classes in masters.\n",
    "restarunt['has_master_classes_attended'] = 0\n",
    "\n",
    "for index, value in restarunt.iterrows():\n",
    "    if restarunt.loc[index, 'master_classes_attended'] > 0 :\n",
    "        restarunt.loc[index, 'has_master_classes_attended'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guessing gender based on (given) name\n",
    "#import gender_guesser.detector as gender # guess gender based on (given) name\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to guess gender\n",
    "#for name in restarunt['first_name']:\n",
    " #   guess = gender.Detector().get_gender(name)\n",
    "    #print(guess)\n",
    "  #  placeholder_lst.append(guess)\n",
    "\n",
    "\n",
    "# converting list into a series\n",
    "#restarunt['gender_guess'] = pd.Series(placeholder_lst)\n",
    "\n",
    "\n",
    "# checking results\n",
    "#restarunt.loc[:, ['first_name','gender_guess']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for val in placeholder_lst:\n",
    " #   print(\"'%s',\" %val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard coded the gender basing on gender guesser package\n",
    "placeholder=['unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'female',\n",
    "'male',\n",
    "'female',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'mostly_female',\n",
    "'female',\n",
    "'female',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'female',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'mostly_female',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'mostly_male',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'male',\n",
    "'andy',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'female',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'male',\n",
    "'unknown',\n",
    "'unknown',\n",
    "'female',\n",
    "'unknown',\n",
    "'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list into a series\n",
    "restarunt['gender_guess'] = pd.Series(placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown          1385\n",
       "male              381\n",
       "female            125\n",
       "mostly_male        24\n",
       "mostly_female      21\n",
       "andy               10\n",
       "Name: gender_guess, dtype: int64"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restarunt['gender_guess'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding categorical variables\n",
    "one_hot_gender_guess      = pd.get_dummies(restarunt['gender_guess'])\n",
    "\n",
    "# dropping categorical variables after they've been encoded\n",
    "restarunt = restarunt.drop('gender_guess', axis = 1)\n",
    "\n",
    "# joining codings together\n",
    "restarunt = restarunt.join([one_hot_gender_guess])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restarunt.loc[ : , 'FREQ_SPL_ORDS' ] = (restarunt.loc[ : , 'TOTAL_MEALS_ORDERED' ]/\n",
    " #                                                  restarunt.loc[ : ,'UNIQUE_MEALS_PURCH' ]).round(2)\n",
    "\n",
    "restarunt.loc[ : , 'complnt_mgmn' ] = (restarunt.loc[ : , 'contacts_w_customer_service' ]/\n",
    "                                              restarunt.loc[ : , 'total_meals_ordered' ]).round(2)\n",
    "\n",
    "#restarunt.loc[ : , 'PROBLM_ORDRNG' ] = ((restarunt.loc[ : ,'EARLY_DELIVERIES'] + chef.loc[ : , 'LATE_DELIVERIES' ])/\n",
    "#                                    restarunt.loc[ : ,'TOTAL_MEALS_ORDERED' ]).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "restarunt['log_pc_logins'] = np.log10(restarunt['pc_logins'])\n",
    "restarunt['log_total_meals_ordered'] = np.log10(restarunt['total_meals_ordered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restarunt.to_excel(\"restarunt.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part IV: Predictive Modeling </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1946, 45)"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restarunt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_sell_success             1.00\n",
      "professional                   0.19\n",
      "len_of_name                    0.18\n",
      "cancellations_before_noon      0.16\n",
      "total_cancellations            0.14\n",
      "male                           0.11\n",
      "mobile_number                  0.10\n",
      "tastes_and_preferences         0.08\n",
      "refrigerated_locker            0.07\n",
      "log_pc_logins                  0.05\n",
      "has_master_classes_attended    0.05\n",
      "personal                       0.04\n",
      "pc_logins                      0.04\n",
      "mostly_male                    0.04\n",
      "package_locker                 0.04\n",
      "contacts_w_customer_service    0.04\n",
      "master_classes_attended        0.04\n",
      "avg_prep_vid_time              0.03\n",
      "median_meal_rating             0.03\n",
      "largest_order_size             0.02\n",
      "early_deliveries               0.02\n",
      "log_total_meals_ordered        0.02\n",
      "late_deliveries                0.01\n",
      "total_deliveries               0.01\n",
      "total_meals_ordered            0.01\n",
      "total_photos_viewed            0.01\n",
      "avg_time_per_site_visit        0.01\n",
      "revenue                        0.00\n",
      "unique_meals_purch             0.00\n",
      "product_categories_viewed      0.00\n",
      "weekly_plan                   -0.01\n",
      "complnt_mgmn                  -0.01\n",
      "andy                          -0.01\n",
      "avg_revenue_per_order         -0.02\n",
      "mostly_female                 -0.02\n",
      "unknown                       -0.04\n",
      "avg_clicks_per_visit          -0.04\n",
      "mobile_logins                 -0.05\n",
      "cancellations_after_noon      -0.05\n",
      "female                        -0.10\n",
      "junk                          -0.28\n",
      "Name: cross_sell_success, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# creating a (Pearson) correlation matrix\n",
    "df_corr = restarunt.corr().round(2)\n",
    "\n",
    "\n",
    "# printing (Pearson) correlations with SalePrice\n",
    "print(df_corr.loc['cross_sell_success'].sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue +\n",
      "total_meals_ordered +\n",
      "unique_meals_purch +\n",
      "contacts_w_customer_service +\n",
      "product_categories_viewed +\n",
      "avg_time_per_site_visit +\n",
      "mobile_number +\n",
      "cancellations_before_noon +\n",
      "cancellations_after_noon +\n",
      "tastes_and_preferences +\n",
      "pc_logins +\n",
      "mobile_logins +\n",
      "weekly_plan +\n",
      "early_deliveries +\n",
      "late_deliveries +\n",
      "package_locker +\n",
      "refrigerated_locker +\n",
      "avg_prep_vid_time +\n",
      "largest_order_size +\n",
      "master_classes_attended +\n",
      "median_meal_rating +\n",
      "avg_clicks_per_visit +\n",
      "total_photos_viewed +\n",
      "avg_revenue_per_order +\n",
      "total_deliveries +\n",
      "total_cancellations +\n",
      "junk +\n",
      "personal +\n",
      "professional +\n",
      "len_of_name +\n",
      "has_master_classes_attended +\n",
      "andy +\n",
      "female +\n",
      "male +\n",
      "mostly_female +\n",
      "mostly_male +\n",
      "unknown +\n",
      "complnt_mgmn +\n",
      "log_pc_logins +\n",
      "log_total_meals_ordered +\n"
     ]
    }
   ],
   "source": [
    "restarunt_explanatory = restarunt.copy()\n",
    "\n",
    "\n",
    "# dropping SalePrice and Order from the explanatory variable set\n",
    "restarunt_explanatory = restarunt.drop(['cross_sell_success','name','email','first_name','family_name'], axis = 1)\n",
    "\n",
    "\n",
    "# formatting each explanatory variable for statsmodels\n",
    "for val in restarunt_explanatory:\n",
    "    print(val,'+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from sklearn.linear_model import LinearRegression # linear regression (scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring explanatory variables\n",
    "restarunt_data = restarunt.drop(['cross_sell_success','name','email','first_name','family_name'], axis = 1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "restarunt_response = restarunt.loc[ : , 'cross_sell_success']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split with stratification\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            restarunt_data,\n",
    "            restarunt_response,\n",
    "            test_size    = 0.25,\n",
    "            random_state = 219,\n",
    "            stratify     = restarunt_response)\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "restarunt_train = pd.concat([x_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Response Variable Proportions (Training Set)\n",
      "--------------------------------------------\n",
      "1    0.68\n",
      "0    0.32\n",
      "Name: cross_sell_success, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "Response Variable Proportions (Testing Set)\n",
      "--------------------------------------------\n",
      "1    0.68\n",
      "0    0.32\n",
      "Name: cross_sell_success, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "\n",
    "Response Variable Proportions (Training Set)\n",
    "--------------------------------------------\n",
    "{y_train.value_counts(normalize = True).round(decimals = 2)}\n",
    "\n",
    "\n",
    "\n",
    "Response Variable Proportions (Testing Set)\n",
    "--------------------------------------------\n",
    "{y_test.value_counts(normalize = True).round(decimals = 2)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Logistic Regression</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532535\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>cross_sell_success</td> <th>  No. Observations:  </th>  <td>  1459</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  1446</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>        <th>  Df Model:          </th>  <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 28 Jan 2021</td>  <th>  Pseudo R-squ.:     </th>  <td>0.1520</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:18:23</td>      <th>  Log-Likelihood:    </th> <td> -776.97</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>        <th>  LL-Null:           </th> <td> -916.19</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>1.550e-52</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                 <td>   -4.4269</td> <td>    1.061</td> <td>   -4.171</td> <td> 0.000</td> <td>   -6.507</td> <td>   -2.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>len_of_name</th>               <td>    0.0803</td> <td>    0.013</td> <td>    6.206</td> <td> 0.000</td> <td>    0.055</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mobile_number</th>             <td>    0.9249</td> <td>    0.178</td> <td>    5.185</td> <td> 0.000</td> <td>    0.575</td> <td>    1.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cancellations_before_noon</th> <td>    0.2815</td> <td>    0.047</td> <td>    5.991</td> <td> 0.000</td> <td>    0.189</td> <td>    0.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tastes_and_preferences</th>    <td>    0.3825</td> <td>    0.137</td> <td>    2.794</td> <td> 0.005</td> <td>    0.114</td> <td>    0.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_pc_logins</th>             <td>    3.1997</td> <td>    1.349</td> <td>    2.371</td> <td> 0.018</td> <td>    0.555</td> <td>    5.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>early_deliveries</th>          <td>    0.0616</td> <td>    0.028</td> <td>    2.211</td> <td> 0.027</td> <td>    0.007</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>avg_prep_vid_time</th>         <td>    0.0026</td> <td>    0.001</td> <td>    2.061</td> <td> 0.039</td> <td>    0.000</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>refrigerated_locker</th>       <td>    0.5324</td> <td>    0.212</td> <td>    2.517</td> <td> 0.012</td> <td>    0.118</td> <td>    0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>junk</th>                      <td>   -1.3282</td> <td>    0.159</td> <td>   -8.350</td> <td> 0.000</td> <td>   -1.640</td> <td>   -1.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>professional</th>              <td>    0.6028</td> <td>    0.146</td> <td>    4.140</td> <td> 0.000</td> <td>    0.317</td> <td>    0.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>                      <td>    0.4873</td> <td>    0.168</td> <td>    2.907</td> <td> 0.004</td> <td>    0.159</td> <td>    0.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>female</th>                    <td>   -0.6332</td> <td>    0.240</td> <td>   -2.639</td> <td> 0.008</td> <td>   -1.104</td> <td>   -0.163</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:     cross_sell_success   No. Observations:                 1459\n",
       "Model:                          Logit   Df Residuals:                     1446\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Thu, 28 Jan 2021   Pseudo R-squ.:                  0.1520\n",
       "Time:                        12:18:23   Log-Likelihood:                -776.97\n",
       "converged:                       True   LL-Null:                       -916.19\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.550e-52\n",
       "=============================================================================================\n",
       "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------\n",
       "Intercept                    -4.4269      1.061     -4.171      0.000      -6.507      -2.347\n",
       "len_of_name                   0.0803      0.013      6.206      0.000       0.055       0.106\n",
       "mobile_number                 0.9249      0.178      5.185      0.000       0.575       1.274\n",
       "cancellations_before_noon     0.2815      0.047      5.991      0.000       0.189       0.374\n",
       "tastes_and_preferences        0.3825      0.137      2.794      0.005       0.114       0.651\n",
       "log_pc_logins                 3.1997      1.349      2.371      0.018       0.555       5.844\n",
       "early_deliveries              0.0616      0.028      2.211      0.027       0.007       0.116\n",
       "avg_prep_vid_time             0.0026      0.001      2.061      0.039       0.000       0.005\n",
       "refrigerated_locker           0.5324      0.212      2.517      0.012       0.118       0.947\n",
       "junk                         -1.3282      0.159     -8.350      0.000      -1.640      -1.016\n",
       "professional                  0.6028      0.146      4.140      0.000       0.317       0.888\n",
       "male                          0.4873      0.168      2.907      0.004       0.159       0.816\n",
       "female                       -0.6332      0.240     -2.639      0.008      -1.104      -0.163\n",
       "=============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" cross_sell_success ~\n",
    "len_of_name +\n",
    "mobile_number +\n",
    "cancellations_before_noon +\n",
    "tastes_and_preferences +\n",
    "log_pc_logins +\n",
    "early_deliveries +\n",
    "avg_prep_vid_time+\n",
    "refrigerated_locker+\n",
    "junk +\n",
    "professional +\n",
    "male  +\n",
    "female \n",
    " \"\"\",\n",
    "                                        data    = restarunt_train)\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using different combination of x- variables\n",
    "logit_sig = ['mobile_number','total_cancellations',\n",
    "            'tastes_and_preferences','pc_logins','early_deliveries','refrigerated_locker',\n",
    "            'avg_prep_vid_time','junk','personal']\n",
    "logit_sig2 = ['mobile_number','cancellations_before_noon',\n",
    "            'tastes_and_preferences','log_pc_logins','early_deliveries','avg_prep_vid_time',\n",
    "              'junk','personal','len_of_name','refrigerated_locker','female','male'] \n",
    "logit_sig3 = ['mobile_number','cancellations_before_noon',\n",
    "            'tastes_and_preferences','pc_logins','early_deliveries','avg_prep_vid_time',\n",
    "              'junk','personal','len_of_name','refrigerated_locker','unknown','male']\n",
    "logit_sig4 = [\"mobile_number\",\"cancellations_before_noon\",\"tastes_and_preferences\",\n",
    "                   \"contacts_w_customer_service\",\"pc_logins\",\n",
    "                   \"refrigerated_locker\",\"junk\",\"personal\",\"avg_revenue_per_order\"\n",
    "              ,\"len_of_name\",\"early_deliveries\"]\n",
    "logit_sig5 = ['mobile_number','cancellations_before_noon',\n",
    "            'tastes_and_preferences','pc_logins','early_deliveries','refrigerated_locker',\n",
    "              'junk','personal','len_of_name','has_master_classes_attended','female','male'] \n",
    "logit_sig6 = ['mobile_number','cancellations_before_noon',\n",
    "            'tastes_and_preferences','pc_logins','early_deliveries','avg_prep_vid_time',\n",
    "              'junk','professional','len_of_name','refrigerated_locker','male','female']\n",
    "logit_sig7 = ['total_meals_ordered' , \n",
    " 'mobile_number' , \n",
    " 'cancellations_before_noon' , \n",
    " 'tastes_and_preferences' ,\n",
    " 'early_deliveries' ,\n",
    " 'refrigerated_locker' , \n",
    " 'log_total_meals_ordered' , \n",
    " 'log_pc_logins' , \n",
    " 'complnt_mgmn' , \n",
    " 'personal' , \n",
    " 'junk',\n",
    " 'len_of_name' ,\n",
    " 'male',\n",
    " 'female'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Training ACCURACY: 0.7457\n",
      "LogReg Testing  ACCURACY: 0.7495\n",
      "LogReg Train-Test Gap   : 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lingi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# train/test split with the full model\n",
    "restarunt_data   =  restarunt.loc[ : , logit_sig7]\n",
    "restarunt_target =  restarunt.loc[ : , 'cross_sell_success']\n",
    "\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            restarunt_data,\n",
    "            restarunt_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = restarunt_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix         # confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 62\n",
      "False Positives: 94\n",
      "False Negatives: 28\n",
      "True Positives : 303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score            # auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6564\n"
     ]
    }
   ],
   "source": [
    "# area under the roc curve (auc)\n",
    "print(roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4))\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('intercept', -0.51)\n",
      "('mobile_number', 0.0)\n",
      "('total_cancellations', 0.86)\n",
      "('tastes_and_preferences', 0.27)\n",
      "('pc_logins', 0.31)\n",
      "('early_deliveries', 0.06)\n",
      "('refrigerated_locker', 0.49)\n",
      "('avg_prep_vid_time', -0.16)\n",
      "('junk', -0.16)\n",
      "('personal', -0.15)\n"
     ]
    }
   ],
   "source": [
    "# zipping each feature name to its coefficient\n",
    "logreg_model_values = zip(restarunt[logit_sig].columns,\n",
    "                          logreg_fit.coef_.ravel().round(decimals = 2))\n",
    "\n",
    "\n",
    "# setting up a placeholder list to store model features\n",
    "logreg_model_lst = [('intercept', logreg_fit.intercept_[0].round(decimals = 2))]\n",
    "\n",
    "\n",
    "# printing out each feature-coefficient pair one by one\n",
    "for val in logreg_model_values:\n",
    "    logreg_model_lst.append(val)\n",
    "    \n",
    "\n",
    "# checking the results\n",
    "for pair in logreg_model_lst:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>CART Tree</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for classification trees\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO           # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus                                     # interprets dot objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# plot_feature_importances\n",
    "########################################\n",
    "def plot_feature_importances(model, train, export = False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 1.0\n",
      "Full Tree Testing ACCURACY : 0.6653\n",
      "Full Tree AUC Score: 0.625\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                    y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                    y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 80\n",
      "False Positives: 76\n",
      "False Negatives: 87\n",
      "True Positives : 244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7505\n",
      "Testing  ACCURACY: 0.77\n",
      "AUC Score        : 0.7088\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 4,\n",
    "                                     min_samples_leaf = 25,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 84\n",
      "False Positives: 72\n",
      "False Negatives: 40\n",
      "True Positives : 291\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(pruned_tree_fit,\n",
    "                         train  = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model         AUC Score      TN, FP, FN, TP\n",
      "-----         ---------      --------------\n",
      "Logistic      0.6564         (62, 94, 28, 303)\n",
      "Full Tree     0.625         (80, 76, 87, 244)\n",
      "Pruned Tree   0.7088         (84, 72, 40, 291)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(62, 94, 28, 303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>(80, 76, 87, 244)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(84, 72, 40, 291)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0     Logistic     0.6564             0.7457            0.7495  (62, 94, 28, 303)\n",
       "1    Full Tree     0.6250             1.0000            0.6653  (80, 76, 87, 244)\n",
       "2  Pruned Tree     0.7088             0.7505            0.7700  (84, 72, 40, 291)"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing results\n",
    "print(f\"\"\"\n",
    "Model         AUC Score      TN, FP, FN, TP\n",
    "-----         ---------      --------------\n",
    "Logistic      {logreg_auc_score}         {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "Full Tree     {full_tree_auc_score}         {full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp}\n",
    "Pruned Tree   {pruned_tree_auc_score}         {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Full Tree', 'Pruned Tree'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, full_tree_auc_score, pruned_tree_auc_score],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, full_tree_train_score,\n",
    "                           pruned_tree_train_score],\n",
    "           \n",
    "    'Testing Accuracy'  : [logreg_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Hyperparameter Tuned Logistic Regression </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# RandomizedSearchCV\n",
    "########################################\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "#C_space          = pd.np.arange(0.1, 5.0, 0.1)\n",
    "#warm_start_space = [True, False]\n",
    "#solver_space     = ['newton-cg', 'sag', 'lbfgs']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'C'          : C_space,\n",
    " #             'warm_start' : warm_start_space,\n",
    "  #            'solver'     : solver_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#lr_tuned = LogisticRegression(random_state = 219,\n",
    "#                              max_iter     = 4000)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    " #                                param_distributions = param_grid, # parameters to tune\n",
    "  #                               cv                  = 3,          # how many folds in cross-validation\n",
    "   #                              n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "    #                             random_state        = 219,        # starting point for random sequence\n",
    "     #                            scoring = make_scorer(\n",
    "      #                                     roc_auc_score,\n",
    "       #                                    needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#lr_tuned_cv.fit(restarunt_data, restarunt_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "#print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking the best estimator for the model\n",
    "#lr_tuned_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Tunning Settings for each variable list is ran and stored here to save processing time </strong> <br>\n",
    "LogisticRegression(C=4.3999999999999995, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=4000, multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=219, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False) -> log_sig <br><br>\n",
    "LogisticRegression(C=4.8, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=4000,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=219, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False) -> log_sig2 <br><br>\n",
    "LogisticRegression(C=2.5000000000000004, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=4000, multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=219, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=True)     <br>     \n",
    "LogisticRegression(C=4.8, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=4000,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=219, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False) -> log_sig6         <br><br>\n",
    "LogisticRegression(C=3.0000000000000004, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=4000, multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=219, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False) -> log_sig7                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7553\n",
      "Testing  ACCURACY: 0.7536\n",
      "AUC Score        : 0.6679\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "lr_tuned = LogisticRegression(C=3.0000000000000004, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=4000, multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=219, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "lr_tuned.fit(restarunt_data, restarunt_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 67\n",
      "False Positives: 89\n",
      "False Negatives: 31\n",
      "True Positives : 300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(62, 94, 28, 303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>(80, 76, 87, 244)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(84, 72, 40, 291)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.7536</td>\n",
       "      <td>(67, 89, 31, 300)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0     Logistic     0.6564             0.7457            0.7495  (62, 94, 28, 303)\n",
       "1    Full Tree     0.6250             1.0000            0.6653  (80, 76, 87, 244)\n",
       "2  Pruned Tree     0.7088             0.7505            0.7700  (84, 72, 40, 291)\n",
       "3     Tuned LR     0.6679             0.7553            0.7536  (67, 89, 31, 300)"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "lr_train_acc = lr_tuned.score(x_train, y_train).round(4)\n",
    "lr_test_acc  = lr_tuned.score(x_test, y_test).round(4)\n",
    "lr_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = lr_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned LR',\n",
    "                           'Training Accuracy' : lr_train_acc,\n",
    "                           'Testing Accuracy'  : lr_test_acc,\n",
    "                           'AUC Score'         : lr_auc,\n",
    "                           'Confusion Matrix'  : (lr_tuned_tn,\n",
    "                                                  lr_tuned_fp,\n",
    "                                                  lr_tuned_fn,\n",
    "                                                  lr_tuned_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tuned CART Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#criterion_space = ['gini', 'entropy']\n",
    "#splitter_space  = ['best', 'random']\n",
    "#depth_space     = pd.np.arange(1, 25, 1)\n",
    "#leaf_space      = pd.np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'criterion'        : criterion_space,\n",
    "#              'splitter'         : splitter_space,\n",
    "#              'max_depth'        : depth_space,\n",
    "#              'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# RandomizedSearchCV object\n",
    "#tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                   param_distributions   = param_grid,\n",
    "#                                   cv                    = 3,\n",
    "#                                   n_iter                = 1000,\n",
    "#                                   random_state          = 219,\n",
    "#                                   scoring = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#tuned_tree_cv.fit(restarunt_data, restarunt_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_tree_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=41, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=219, splitter='best')-> log_sig2 <br> <br>\n",
    "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=41, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=219, splitter='best') -> log_sig6    <br> <br>  \n",
    "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=14, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=219, splitter='random') -> log_sig7                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7656\n",
      "Testing  ACCURACY: 0.7823\n",
      "AUC Score        : 0.7382\n"
     ]
    }
   ],
   "source": [
    "#####################  FINAL MODEL ##############\n",
    "##### NAME : TUNED TREES ###########\n",
    "\n",
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=24,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=14, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=219, splitter='random')\n",
    "\n",
    "tree_tuned_fit = tree_tuned.fit(restarunt_data, restarunt_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = tree_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 96\n",
      "False Positives: 60\n",
      "False Negatives: 46\n",
      "True Positives : 285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#####################  FINAL MODEL ##############\n",
    "\n",
    "####### CONFUSION MATRIX #########\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting feature importance\n",
    "plot_feature_importances(pruned_tree_fit,\n",
    "                         train  = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(62, 94, 28, 303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>(80, 76, 87, 244)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(84, 72, 40, 291)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.7536</td>\n",
       "      <td>(67, 89, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.7823</td>\n",
       "      <td>(96, 60, 46, 285)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0     Logistic     0.6564             0.7457            0.7495  (62, 94, 28, 303)\n",
       "1    Full Tree     0.6250             1.0000            0.6653  (80, 76, 87, 244)\n",
       "2  Pruned Tree     0.7088             0.7505            0.7700  (84, 72, 40, 291)\n",
       "3     Tuned LR     0.6679             0.7553            0.7536  (67, 89, 31, 300)\n",
       "4   Tuned Tree     0.7382             0.7656            0.7823  (96, 60, 46, 285)"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "tree_train_acc = tree_tuned.score(x_train, y_train).round(4)\n",
    "tree_test_acc  = tree_tuned.score(x_test, y_test).round(4)\n",
    "tree_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = tree_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned Tree',\n",
    "                           'Training Accuracy' : tree_train_acc,\n",
    "                           'Testing Accuracy'  : tree_test_acc,\n",
    "                           'AUC Score'         : tree_auc,\n",
    "                           'Confusion Matrix'  : (tuned_tree_tn,\n",
    "                                                  tuned_tree_fp,\n",
    "                                                  tuned_tree_fn,\n",
    "                                                  tuned_tree_tp)},\n",
    "                           ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Random Forest</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier     # random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 1000,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 1.0\n",
      "Testing  ACCURACY: 0.7351\n",
      "AUC Score        : 0.6509\n"
     ]
    }
   ],
   "source": [
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting feature importances\n",
    "plot_feature_importances(rf_default_fit,\n",
    "                         train = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 65\n",
      "False Positives: 91\n",
      "False Negatives: 38\n",
      "True Positives : 293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(62, 94, 28, 303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>(80, 76, 87, 244)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(84, 72, 40, 291)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.7536</td>\n",
       "      <td>(67, 89, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.7823</td>\n",
       "      <td>(96, 60, 46, 285)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.6509</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>(65, 91, 38, 293)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0              Logistic     0.6564             0.7457            0.7495  (62, 94, 28, 303)\n",
       "1             Full Tree     0.6250             1.0000            0.6653  (80, 76, 87, 244)\n",
       "2           Pruned Tree     0.7088             0.7505            0.7700  (84, 72, 40, 291)\n",
       "3              Tuned LR     0.6679             0.7553            0.7536  (67, 89, 31, 300)\n",
       "4            Tuned Tree     0.7382             0.7656            0.7823  (96, 60, 46, 285)\n",
       "5  Random Forest (Full)     0.6509             1.0000            0.7351  (65, 91, 38, 293)"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "rf_train_acc = rf_default_fit.score(x_train, y_train).round(4)\n",
    "rf_test_acc  = rf_default_fit.score(x_test, y_test).round(4)\n",
    "rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                             y_score = rf_default_fit_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Random Forest (Full)',\n",
    "                           'Training Accuracy'  : rf_train_acc,\n",
    "                           'Testing Accuracy'   : rf_test_acc,\n",
    "                           'AUC Score'          : rf_auc,\n",
    "                           'Confusion Matrix'   : (rf_tn,\n",
    "                                                   rf_fp,\n",
    "                                                   rf_fn,\n",
    "                                                   rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tuned Random Forest</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING the training data\n",
    "#rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "#rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "#estimator_space  = pd.np.arange(100, 1100, 250) #start from 100 and go till 1100 with increment of 250\n",
    "#leaf_space       = pd.np.arange(1, 31, 10)\n",
    "#criterion_space  = ['gini', 'entropy']\n",
    "#bootstrap_space  = [True, False]\n",
    "#warm_start_space = [True, False]\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'n_estimators'     : estimator_space,\n",
    "#              'min_samples_leaf' : leaf_space,\n",
    "#              'criterion'        : criterion_space,\n",
    "#              'bootstrap'        : bootstrap_space,\n",
    "#              'warm_start'       : warm_start_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                               param_distributions = param_grid,\n",
    "#                               cv         = 3,\n",
    "#                               n_iter     = 1000,\n",
    "#                               scoring    = make_scorer(roc_auc_score,\n",
    "#                                            needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#forest_cv.fit(restarunt_data, restarunt_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "#printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best estimators based on RandomizedSearchCV\n",
    "#forest_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Tunning Settings for each variable list is ran and stored here to save processing time </strong> <br>\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True) -> log_sig <br><br>\n",
    "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True) -> log_sig2  <br><br>\n",
    "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True)   <br><br>\n",
    "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True) -> log_sig5 <br><br>\n",
    "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=21, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True) -> log_sig6 <br><br>\n",
    "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True) -> log_sig7               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.8095\n",
      "Forest Tuned Testing  ACCURACY: 0.8398\n",
      "Forest Tuned AUC Score        : 0.7737\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# copy/pasting in the best_estimator_ results\n",
    "# to avoid running another RandomizedSearch\n",
    "forest_tuned = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "forest_tuned_fit = forest_tuned.fit(restarunt_data, restarunt_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                   y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting feature importances\n",
    "plot_feature_importances(forest_tuned_fit,\n",
    "                         train = x_train,\n",
    "                         export = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 92\n",
      "False Positives: 64\n",
      "False Negatives: 14\n",
      "True Positives : 317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(62, 94, 28, 303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>(80, 76, 87, 244)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(84, 72, 40, 291)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.7536</td>\n",
       "      <td>(67, 89, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.7823</td>\n",
       "      <td>(96, 60, 46, 285)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.6509</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>(65, 91, 38, 293)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>(92, 64, 14, 317)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0                    Logistic     0.6564             0.7457            0.7495  (62, 94, 28, 303)\n",
       "1                   Full Tree     0.6250             1.0000            0.6653  (80, 76, 87, 244)\n",
       "2                 Pruned Tree     0.7088             0.7505            0.7700  (84, 72, 40, 291)\n",
       "3                    Tuned LR     0.6679             0.7553            0.7536  (67, 89, 31, 300)\n",
       "4                  Tuned Tree     0.7382             0.7656            0.7823  (96, 60, 46, 285)\n",
       "5        Random Forest (Full)     0.6509             1.0000            0.7351  (65, 91, 38, 293)\n",
       "6  Tuned Random Forest (Full)     0.7737             0.8095            0.8398  (92, 64, 14, 317)"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "tuned_rf_train_acc = forest_tuned_fit.score(x_train, y_train).round(4)\n",
    "tuned_rf_test_acc  = forest_tuned_fit.score(x_test, y_test).round(4)\n",
    "tuned_rf_auc       = roc_auc_score(y_true  = y_test,\n",
    "                                   y_score = forest_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'         : 'Tuned Random Forest (Full)',\n",
    "                           'Training Accuracy'  : tuned_rf_train_acc,\n",
    "                           'Testing Accuracy'   : tuned_rf_test_acc,\n",
    "                           'AUC Score'          : tuned_rf_auc,\n",
    "                           'Confusion Matrix'   : (tuned_rf_tn,\n",
    "                                                   tuned_rf_fp,\n",
    "                                                   tuned_rf_fn,\n",
    "                                                   tuned_rf_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Gradient Boosted Machines</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier # gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.817\n",
      "Testing ACCURACY : 0.7515\n",
      "AUC Score        : 0.6715\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 70\n",
      "False Positives: 86\n",
      "False Negatives: 35\n",
      "True Positives : 296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(62, 94, 28, 303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>(80, 76, 87, 244)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(84, 72, 40, 291)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.7536</td>\n",
       "      <td>(67, 89, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.7823</td>\n",
       "      <td>(96, 60, 46, 285)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.6509</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>(65, 91, 38, 293)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>(92, 64, 14, 317)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM (Full)</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>0.8170</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>(70, 86, 35, 296)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0                    Logistic     0.6564             0.7457            0.7495  (62, 94, 28, 303)\n",
       "1                   Full Tree     0.6250             1.0000            0.6653  (80, 76, 87, 244)\n",
       "2                 Pruned Tree     0.7088             0.7505            0.7700  (84, 72, 40, 291)\n",
       "3                    Tuned LR     0.6679             0.7553            0.7536  (67, 89, 31, 300)\n",
       "4                  Tuned Tree     0.7382             0.7656            0.7823  (96, 60, 46, 285)\n",
       "5        Random Forest (Full)     0.6509             1.0000            0.7351  (65, 91, 38, 293)\n",
       "6  Tuned Random Forest (Full)     0.7737             0.8095            0.8398  (92, 64, 14, 317)\n",
       "7                  GBM (Full)     0.6715             0.8170            0.7515  (70, 86, 35, 296)"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "gbm_train_acc = full_gbm_default_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = full_gbm_default_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'       : 'GBM (Full)',\n",
    "                          'Training Accuracy' : gbm_train_acc,\n",
    "                          'Testing Accuracy'  : gbm_test_acc,\n",
    "                          'AUC Score'         : gbm_auc,\n",
    "                          'Confusion Matrix'  : (gbm_default_tn,\n",
    "                                                 gbm_default_fp,\n",
    "                                                 gbm_default_fn,\n",
    "                                                 gbm_default_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tuned GBM </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring a hyperparameter space\n",
    "#learn_space        = pd.np.arange(0.1, 2.0, 0.2)\n",
    "#estimator_space    = pd.np.arange(100, 200, 25)\n",
    "#depth_space        = pd.np.arange(1, 20, 2)\n",
    "#warm_start_space   = [True, False]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "#param_grid = {'learning_rate' : learn_space,\n",
    " #             'max_depth'     : depth_space,\n",
    "  #            'n_estimators'  : estimator_space,\n",
    "   #           'warm_start'     : warm_start_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "#full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "#full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    " #                          param_distributions = param_grid,\n",
    "  #                         cv                  = 3,\n",
    "   #                        n_iter              = 500,\n",
    "    #                       random_state        = 219,\n",
    "     #                      scoring             = make_scorer(roc_auc_score,\n",
    "#                                                 needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "#full_gbm_cv.fit(restarunt_data, restarunt_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "#print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "#print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checking the best estimator for the model\n",
    "#full_gbm_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Tunning Settings for each variable list is ran and stored here to save processing time </strong> <br>\n",
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.9000000000000001, loss='deviance',\n",
    "                           max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='auto',\n",
    "                           random_state=219, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0, warm_start=True) -> log_sig <br><br>\n",
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.30000000000000004, loss='deviance',\n",
    "                           max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='auto',\n",
    "                           random_state=219, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False) -> log_sig2   <br><br>\n",
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.1, loss='deviance', max_depth=1,\n",
    "                           max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='auto',\n",
    "                           random_state=219, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False)          <br>              \n",
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "                           learning_rate=1.3000000000000003, loss='deviance',\n",
    "                           max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=125,\n",
    "                           n_iter_no_change=None, presort='auto',\n",
    "                           random_state=219, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False) -> log_sig5   <br><br>\n",
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "                           learning_rate=1.1000000000000003, loss='deviance',\n",
    "                           max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=125,\n",
    "                           n_iter_no_change=None, presort='auto',\n",
    "                           random_state=219, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False) -> log_sig6 <br><br>\n",
    "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.9000000000000001, loss='deviance',\n",
    "                           max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='auto',\n",
    "                           random_state=219, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0, warm_start=True) -> log_sig7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7868\n",
      "Testing  ACCURACY: 0.7885\n",
      "AUC Score        : 0.7173\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "\n",
    "# I made several attempts to hyperparameter tuning\n",
    "gbm_tuned = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.9000000000000001, loss='deviance',\n",
    "                           max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='auto',\n",
    "                           random_state=219, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0, warm_start=True)\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "gbm_tuned_fit = gbm_tuned.fit(restarunt_data, restarunt_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "True Negatives : 81\n",
      "False Positives: 75\n",
      "False Negatives: 28\n",
      "True Positives : 303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Models Performance Comparison </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>AUC Score</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>(62, 94, 28, 303)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Full Tree</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6653</td>\n",
       "      <td>(80, 76, 87, 244)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pruned Tree</td>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.7505</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>(84, 72, 40, 291)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned LR</td>\n",
       "      <td>0.6679</td>\n",
       "      <td>0.7553</td>\n",
       "      <td>0.7536</td>\n",
       "      <td>(67, 89, 31, 300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Tree</td>\n",
       "      <td>0.7382</td>\n",
       "      <td>0.7656</td>\n",
       "      <td>0.7823</td>\n",
       "      <td>(96, 60, 46, 285)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest (Full)</td>\n",
       "      <td>0.6509</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>(65, 91, 38, 293)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuned Random Forest (Full)</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>(92, 64, 14, 317)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBM (Full)</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>0.8170</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>(70, 86, 35, 296)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tuned GBM</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>(81, 75, 28, 303)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Name  AUC Score  Training Accuracy  Testing Accuracy   Confusion Matrix\n",
       "0                    Logistic     0.6564             0.7457            0.7495  (62, 94, 28, 303)\n",
       "1                   Full Tree     0.6250             1.0000            0.6653  (80, 76, 87, 244)\n",
       "2                 Pruned Tree     0.7088             0.7505            0.7700  (84, 72, 40, 291)\n",
       "3                    Tuned LR     0.6679             0.7553            0.7536  (67, 89, 31, 300)\n",
       "4                  Tuned Tree     0.7382             0.7656            0.7823  (96, 60, 46, 285)\n",
       "5        Random Forest (Full)     0.6509             1.0000            0.7351  (65, 91, 38, 293)\n",
       "6  Tuned Random Forest (Full)     0.7737             0.8095            0.8398  (92, 64, 14, 317)\n",
       "7                  GBM (Full)     0.6715             0.8170            0.7515  (70, 86, 35, 296)\n",
       "8                   Tuned GBM     0.7173             0.7868            0.7885  (81, 75, 28, 303)"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declaring model performance objects\n",
    "gbm_train_acc = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_acc  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "gbm_auc       = roc_auc_score(y_true  = y_test,\n",
    "                              y_score = gbm_tuned_pred).round(4)\n",
    "\n",
    "\n",
    "# appending to model_performance\n",
    "model_performance = model_performance.append(\n",
    "                          {'Model Name'        : 'Tuned GBM',\n",
    "                          'Training Accuracy'  : gbm_train_acc,\n",
    "                          'Testing Accuracy'   : gbm_test_acc,\n",
    "                          'AUC Score'          : gbm_auc,\n",
    "                          'Confusion Matrix'   : (gbm_tuned_tn,\n",
    "                                                  gbm_tuned_fp,\n",
    "                                                  gbm_tuned_fn,\n",
    "                                                  gbm_tuned_tp)},\n",
    "                          ignore_index = True)\n",
    "\n",
    "\n",
    "# checking the results\n",
    "model_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><strong>Tuned Random Forest is the best model for this Case with an AUC of 77.37<strong></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
